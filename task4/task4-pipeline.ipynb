{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Linear Regression Model (Part 1)"
   ],
   "id": "f37728056c5c49da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Business Understanding\n",
    "\n",
    "Our aim in the first part of the document is to construct a linear regression model for predicting continuous target variable \"Y house price of unit area\" in Real Estate Valuation dataset.\n",
    "</br>\n",
    "</br>\n",
    "The data is collected from New Taipei City, Taiwan.\n",
    "</br>\n",
    "https://archive.ics.uci.edu/dataset/477/real+estate+valuation+data+set"
   ],
   "id": "9ba44219cebec12f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Understanding"
   ],
   "id": "a798fb8ad5397ef9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-07T17:17:11.139218Z",
     "start_time": "2026-02-07T17:17:07.936335Z"
    }
   },
   "source": [
    "import reg\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "real_estate_valuation = fetch_ucirepo(id=477)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = real_estate_valuation.data.features\n",
    "y = real_estate_valuation.data.targets\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The dataset includes the following six features: transaction date, house age, distance to the nearest MRT station (Mass Rapid Transit), number of convenience stores nearby, latitude, and longitude. Each feature contains 414 entries."
   ],
   "id": "235b9d32e54ee945"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T17:17:11.156078Z",
     "start_time": "2026-02-07T17:17:11.139218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X.info()"
   ],
   "id": "e821b10affd74bfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 414 entries, 0 to 413\n",
      "Data columns (total 6 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   X1 transaction date                     414 non-null    float64\n",
      " 1   X2 house age                            414 non-null    float64\n",
      " 2   X3 distance to the nearest MRT station  414 non-null    float64\n",
      " 3   X4 number of convenience stores         414 non-null    int64  \n",
      " 4   X5 latitude                             414 non-null    float64\n",
      " 5   X6 longitude                            414 non-null    float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 19.5 KB\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The target variable is the house price per unit area. (10,000 New Taiwan Dollars/Ping, where Ping is a local unit, 1 Ping = 3.3 meter squared)"
   ],
   "id": "963d1a5be88fb543"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T17:17:11.165582Z",
     "start_time": "2026-02-07T17:17:11.156078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y.info()"
   ],
   "id": "6d52bde965f66635",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 414 entries, 0 to 413\n",
      "Data columns (total 1 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Y house price of unit area  414 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 3.4 KB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "For linear regression modeling to work, dependencies between feature- and target variables should be mostly linear. Let's examine some of them by plotting them:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61517b615123a9e2"
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(X[\"X3 distance to the nearest MRT station\"], y)\n",
    "plt.xlabel(\"Distance to nearest MRT station\")\n",
    "plt.ylabel(\"House price of unit area\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-07T17:17:11.606248Z",
     "start_time": "2026-02-07T17:17:11.165582Z"
    }
   },
   "id": "93f1562095dc08bc",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39mscatter(X[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX3 distance to the nearest MRT station\u001B[39m\u001B[38;5;124m\"\u001B[39m], y)\n\u001B[0;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDistance to nearest MRT station\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "plt.scatter(X[\"X2 house age\"], y)\n",
    "plt.xlabel(\"House age\")\n",
    "plt.ylabel(\"House price of unit area\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93b3c63e5b7032f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "plt.scatter(X[\"X4 number of convenience stores\"], y)\n",
    "plt.xlabel(\"Number of convenience stores\")\n",
    "plt.ylabel(\"House price of unit area\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be6235f719874740",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We determine that the data features and targets are linearly correlated: for all three cases plotted, the datapoints seem to form a mostly linear overall pattern across feature value ranges. This problem can be modeled using linear regression. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f6cf43693ae638b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Preparation\n",
    "\n",
    "Looking at the feature data, we can see that the values vary widely across different features. To ensure that each feature contributes equally to the model, it is necessary to standardize the features before training the linear regression model."
   ],
   "id": "f98da459a82bd144"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X.head()"
   ],
   "id": "e44ae8ae189e1e09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Before applying standardization, we split the data for training and testing."
   ],
   "id": "5dcab4377d80930c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123\n",
    ")"
   ],
   "id": "aaa930a0baf49989",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n"
   ],
   "id": "ea9e3bde31bf6442",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Modeling"
   ],
   "id": "ac57392735215d37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We use _LinearRegression_ class from sklearn library to train the model with the training data."
   ],
   "id": "a9dc9cb0333df5e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T17:17:11.639759Z",
     "start_time": "2026-02-07T17:17:11.624024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)"
   ],
   "id": "118c116daf171e5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "id": "531f5195d19af786"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T17:17:11.639759Z",
     "start_time": "2026-02-07T17:17:11.639759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "b0 = model.intercept_\n",
    "b0"
   ],
   "id": "46af3664858979d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "b1 = model.coef_[0]\n",
    "b1"
   ],
   "id": "9ff97f1bf72bb65b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Next we have the feature coefficient values ordered from most impactful one to the least.\n",
    "\n",
    "From the coefficient analysis, we can see that the distance to the nearest MRT station has the largest impact on house price among all features. Negative value indicates that the feature negatively impacts on the house price, in this case meaning that houses farther from MRT stations tend to be cheaper.\n",
    "\n",
    "Second most impactful feature is house age. It also has negative impact on the house price, in this case meaning that the older the house is the cheaper it is.\n",
    "\n",
    "Third most impactful feature, which is almost as impactful as the second, is number of convenience stores in the living circle. The circles radius is not mentioned in the dataset, however it is mentioned that stores are in near walking distance. Anyway, this has positive impact on the house price, meaning more stores nearby equals higher house cost.\n",
    "\n",
    "Least impactful features are latitude, transaction date and longitude.\n"
   ],
   "id": "dc2cca06c618ce1e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "coef_df = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Coefficient\": b1\n",
    "})\n",
    "\n",
    "coef_df[\"Abs_Coefficient\"] = coef_df[\"Coefficient\"].abs()\n",
    "coef_df_sorted = coef_df.sort_values(by=\"Abs_Coefficient\", ascending=False) # add temporary absolute value column for sorting correctly\n",
    "coef_df_sorted = coef_df_sorted.drop(columns=\"Abs_Coefficient\")\n",
    "coef_df_sorted"
   ],
   "id": "d315feec58070921",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85c9fdc5a05c9078"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Next we use the regression model to predict house prices with the test data."
   ],
   "id": "27a97fc6601de8b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "preds = model.predict(X_test_scaled)\n",
    "\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "print(\"MAE:\", mae)"
   ],
   "id": "99b9bbbecdb175ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Models mean absolute error value is around 4.96, meaning that on average, the models predictions are off by 4.96 × 10,000 NTD/Ping.\n",
    "\n",
    "In other metrics (Euro/m2) it would be 4.96 * (270 / 3.3) $ \\approx $ 405 Euros off by average per square meter.\n",
    "</br>\n",
    "Where 1 NTD = 0,027 Euro (5.2.2026) and 1 Ping = 3.3 m2.\n",
    "\n"
   ],
   "id": "544c0bb313e465c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In the dataset, average price per Ping is around 37,9 * 10 000 NTD.\n",
    "\n",
    "So in that context, the error percentage is around 13 % for the model."
   ],
   "id": "460a74a6c0b45a88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "avg_price_ping = (y.mean().values[0]) # values[0] so it doesn't return the column name also.\n",
    "print(\"Average price per Ping:\", avg_price_ping)"
   ],
   "id": "b96c93530abadb44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MAE = 4.96\n",
    "\n",
    "error_percentage = MAE / avg_price_ping * 100\n",
    "error_percentage"
   ],
   "id": "7a410c72bd5726c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression Model (Part 2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc47c2ff2586b993"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Business Understanding\n",
    "\n",
    "In part 2, we aim to create a model based on logistic regression that has the capability to predict whether a given apartment is above or below the average price per Ping.\n",
    "\n",
    "As calculated previously, mean apartment price per Ping is around 37,9 * 10 000 NTD. This will act as our cutoff point for the model, whether a price is over or under the mean price.\n",
    "\n",
    "We start over:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c804eed2c71b7fd3"
  },
  {
   "cell_type": "code",
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "# fetch dataset\n",
    "real_estate_valuation = fetch_ucirepo(id=477)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = real_estate_valuation.data.features\n",
    "y = real_estate_valuation.data.targets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c576f6ef7b2e30cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preparation\n",
    "\n",
    "Our first step is to re-encode target values as being under or over mean apartment price per Ping:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1a7158498c44ecc"
  },
  {
   "cell_type": "code",
   "source": [
    "y_binary_encoded = pd.DataFrame() # new empty frame\n",
    "\n",
    "y_binary_encoded[\"house price over mean\"] = y[\"Y house price of unit area\"].map(lambda x: 1 if x >= 37.9 else 0)\n",
    "\n",
    "y_binary_encoded[\"house price over mean\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4de6f42b9773a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we again split the data into training and test sets before standardizing both feature sets (X_train and X_test) separately.\n",
    "\n",
    "We use the new y-target dataframe that's been re-encoded to 1 and 0."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfadd8177d7267de"
  },
  {
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_binary_encoded, test_size=0.2, random_state=123\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76e52683a6ca9230",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a57c1800a253fac5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bab1b244ccebe23d"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# build and fit model\n",
    "reg = LogisticRegression(solver='lbfgs')\n",
    "reg.fit(X_train_scaled,y_train.values.ravel())\n",
    "\n",
    "print(\"Coefficients: \",reg.coef_)\n",
    "print(\"Intercept: \", reg.intercept_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc76073ec953034",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The coefficients show us how each input feature affects the prediction of whether an apartment price is above the mean. Positive numbers increase the probability, negative numbers decrease it.\n",
    "\n",
    "Our model following coefficients:\n",
    "0.31349549, -0.68898701, -2.31007379, 0.62655473, 0.95884062, 0.0836134\n",
    "\n",
    "Each number matches one input feature (in the order they appear in X_train_scaled). \n",
    "For example, the first coefficient (0.313) slightly increases the predicted probability that an apartment is above the mean when the first feature increases, while the third coefficient (-2.310) strongly decreases the probability when the third feature increases.\n",
    "\n",
    "The intercept (-0.583) is the starting point for the prediction when all features are zero. The coefficients adjust this starting value to get the final probability."
   ],
   "id": "f7d1f23de6c5bb2a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation\n",
    "\n",
    "We evaluate the model using 10-fold cross-validation to see how well it predicts whether an apartment price is above or below the mean."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17bc54362946bbbb"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# cross-validation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = cross_val_predict(estimator=reg, X=X, y=y_binary_encoded.values.ravel(), cv=10)\n",
    "\n",
    "cm = confusion_matrix(y_binary_encoded.values.ravel(), y_pred)\n",
    "accuracy = accuracy_score(y_binary_encoded.values.ravel(), y_pred)\n",
    "\n",
    "print(\"Accuracy: %0.2f\" % accuracy)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# visualize confusion matrix\n",
    "plt.matshow(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "# include counts\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, cm[i, j], ha='center', va='center', color='red')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7f89f0f1e642117",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation\n",
    "\n",
    "We validate the logistic regression model by interpreting its performance on the cross-validated predictions. We use 10-fold cross-validation and the model achieved an accuracy of 0.83, which means that the model correctly predicts whether an apartment price is above or below the mean in 83% of cases.\n",
    "\n",
    "The confusion matrix shows the model’s predictions:\n",
    "\n",
    "True Positives (191): apartments correctly predicted to be above the mean price.\n",
    "\n",
    "True Negatives (154): apartments correctly predicted to be below the mean price.\n",
    "\n",
    "False Positives (44): apartments predicted above mean price but actually below\n",
    "\n",
    "False Negatives (25): apartments predicted below mean price but actually above.\n",
    "\n",
    "The model performs quite well, which can be seen from its high accuracy and few incorrect predictions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf599957ec2e57cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
